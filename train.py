# -*- coding: utf-8 -*-
"""SinaiseSistemas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c9QGuDtxvervdM9v7UH8UANO3T-EVO2A
"""

import numpy as np
import pickle
import librosa
import sklearn as sk
import scipy
import os
import pandas as pd
import matplotlib.pyplot as plt
import glob
import joblib
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def get_features(mfcc,mel_spect,y):
  featstack = np.hstack((np.mean(mfcc, axis=1), np.std(mfcc, axis=1), scipy.stats.skew(mfcc, axis = 1), np.max(mfcc, axis = 1), np.median(mfcc, axis = 1), np.min(mfcc, axis = 1)))
  feat2 = librosa.feature.zero_crossing_rate(y)[0]
  feat2stack = np.hstack((np.mean(feat2), np.std(feat2), scipy.stats.skew(feat2, bias=False), np.max(feat2), np.median(feat2), np.min(feat2)))
  feat3 = librosa.feature.spectral_rolloff(y=y)[0] #a frequência abaixo da qual se encontra um certo percentual da energia espectral cumulativa (por padrão, 85%)
  feat3stack = np.hstack((np.mean(feat3), np.std(feat3), scipy.stats.skew(feat3,bias=False), np.max(feat3), np.median(feat3), np.min(feat3)))
  feat4 = librosa.feature.spectral_centroid(y=y)[0]
  feat4stack = np.hstack((np.mean(feat4), np.std(feat4), scipy.stats.skew(feat4, bias=False), np.max(feat4), np.median(feat4), np.min(feat4)))
  feat5 = librosa.feature.spectral_contrast(y=y)[0]
  feat5stack = np.hstack((np.mean(feat5), np.std(feat5), scipy.stats.skew(feat5, bias=False), np.max(feat5), np.median(feat5), np.min(feat5)))
  feat6 = librosa.feature.spectral_bandwidth(y=y)[0]
  feat6stack = np.hstack((np.min(feat6), np.std(feat6), scipy.stats.skew(feat6, bias=False), np.max(feat6), np.median(feat6), np.min(feat6)))
  mfcc_data = pd.Series(np.hstack((featstack, feat2stack, feat3stack, feat4stack, feat5stack, feat6stack)))
  return mfcc_data


def matriz_confusao(labels, c2i, Y_pred, Y_test):
  rotulos = []
  for label in labels:
    rotulos.append(c2i[label])
  cm = sk.metrics.confusion_matrix(Y_test, Y_pred,labels=rotulos)
  cm_disp = sk.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rotulos)
  cm_disp.plot()


file_path = 'audios/**/*.wav'
audiosList = glob.glob(file_path, recursive = True) #carrega todos os arquivos .wav que estão na pasta audios
if not audiosList:
    print("Nenhum arquivo de áudio encontrado. Verifique o caminho.")

#print(audiosList)

all_mfccs = [] #lista de mfccs
names = [] #lista de nomes dos áudios
all_mfcc_datas = []

for audio in audiosList: #percorre todos os arquivos de audio
    #try:
      #obtem o nome do arquivo
      namesparts = audio.split('\\')
      name = namesparts[len(namesparts)-2]
      '''name = name.split('.')
      name = name[0]'''
      print(name)
      names.append(name)


      y, sr = librosa.load(audio, sr=None) #carrega o audio
      '''plt.plot(y)
      plt.title('Sinal')
      plt.xlabel('Tempo (amostras)')
      plt.ylabel('Amplitude')
      plt.show();'''


      spec = np.abs(librosa.stft(y, hop_length=512))
      spec = librosa.amplitude_to_db(spec, ref=np.max)
      '''librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='log')
      plt.colorbar(format='%+2.0f dB')
      plt.title('Spectrogram')
      plt.show();'''
      #calcula e plota o mel spectrogram
      mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)
      mel_spect = librosa.power_to_db(mel_spect, ref=np.max)
      '''librosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time')
      plt.title('Mel Spectrogram')
      plt.colorbar(format='%+2.0f dB')'''

      ##antigo mfccs = librosa.feature.mfcc(y=y,sr=sr, n_mfcc=13)
      mfccs = librosa.feature.mfcc(S=mel_spect,sr=sr, n_mfcc=13) #n_mfcc é a quantidade de coeficientesr
      all_mfccs.append(mfccs)

      all_mfcc_datas.append(get_features(mfccs, mel_spect, y))
      '''plt.figure(figsize=(10, 4))
      librosa.display.specshow(mfccs, x_axis='time')
      plt.colorbar()
      plt.title('MFCC Visualization')
      plt.xlabel('Time')
      plt.ylabel('MFCC coefficients')
      plt.show()'''
    #except Exception as e:
      #print(f'Erro ao processar arquivo')

#all_mfcc_datas = np.array(all_mfcc_datas)

print(all_mfccs[0])

matrix = all_mfcc_datas

#print(matrix)
labels = np.sort(np.unique(names))
c2i = {}
i2c = {}
for i, c in enumerate(labels):
  i2c[i] = c
  c2i[c] = i
#y = np.array([c2i[x] for x in dataframe.name.values])
y = np.array([c2i[x] for x in names])
print(y)

for i in range(len(matrix)):
    for j in range(len(matrix[i])):
      if np.isnan(matrix[i][j]):
        print(i,j)
        matrix[i][j] = 0
#print(X_to_train[0])

scaler = StandardScaler()
X_scaled = scaler.fit_transform(matrix)
pca = PCA(n_components=65).fit(X_scaled)
with open('pca.pkl', 'wb') as pickle_file:
  pickle.dump(pca, pickle_file)
X_pca = pca.transform(X_scaled)

X_train, X_test, Y_train, Y_test = train_test_split(X_pca,y, test_size=0.20, random_state=42, shuffle = True)
svc = SVC()
svc.fit(X_train, Y_train)

svc.score(X_test, Y_test)

Y_pred = svc.predict(X_test)
accuracy = sk.metrics.accuracy_score(Y_test, Y_pred)
print("Parametro de regularização: ", svc.C)
print("kernel: ", svc.kernel)
print("accuracy: ", accuracy)

matriz_confusao(labels,c2i,Y_pred,Y_test)

param = {
    #'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],
    #'gamma': [0.001, 0.01, 0.1, 1, 10],
    'C' : [.1, .4, .6, 1, 2, 3, 100, 200]
}
svm_grid = GridSearchCV(svc, param_grid = param)
svm_grid.fit(X_train, Y_train)

print(svm_grid.best_params_)


novo_svc = SVC(kernel = 'rbf', C = svm_grid.best_params_['C'])
novo_svc.fit(X_train, Y_train)
joblib.dump(novo_svc, 'svm_treinado.pkl')
novo_svc.score(X_test, Y_test)

novo_Y_pred = novo_svc.predict(X_test)
accuracy = sk.metrics.accuracy_score(Y_test, novo_Y_pred)
matriz_confusao(labels, c2i, novo_Y_pred, Y_test)

print(sk.metrics.classification_report(Y_test,novo_Y_pred))